# Make a directory for all the data

mkdir data
cd data

# Downloading the FASTQ-files from ArrayExpress

wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR205/004/ERR2059824/ERR2059824.fastq.gz #sample1
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR205/005/ERR2059825/ERR2059825.fastq.gz #sample10
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR205/006/ERR2059826/ERR2059826.fastq.gz #sample11 
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR205/007/ERR2059827/ERR2059827.fastq.gz #sample12
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR205/008/ERR2059828/ERR2059828.fastq.gz #sample2
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR205/009/ERR2059829/ERR2059829.fastq.gz #sample3
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR205/000/ERR2059830/ERR2059830.fastq.gz #sample4
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR205/001/ERR2059831/ERR2059831.fastq.gz #sample5
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR205/002/ERR2059832/ERR2059832.fastq.gz #sample6
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR205/003/ERR2059833/ERR2059833.fastq.gz #sample7
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR205/004/ERR2059834/ERR2059834.fastq.gz #sample8
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR205/005/ERR2059835/ERR2059835.fastq.gz #sample9

# Alternative way to download the files:

wget https://www.ebi.ac.uk/arrayexpress/files/E-MTAB-5935/E-MTAB-5935.sdrf.txt
cut -f26 E-MTAB-5935.sdrf.txt > column_with_links.txt
tail -n +2 column_with_links.txt > links2download.txt
wget -N -i links2download # Did not run this

#Unzip the files

gunzip *.fastq.gz

# Make a directory for all the sample data

mkdir sequencing_data

# Move all fastq files into the new directory

mv *.fastq ./sequencing_data

# Download the genome of Mycobacterium tuberculosis from NCBI
# Get the files from https://www.ncbi.nlm.nih.gov/genome?LinkName=nuccore_genome&from_uid=444893469, 
# right click on the Download sequences in FASTA format for genome, protein -> genome, copy linkadress
# (This will be located directly in the data foler.)

wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/195/955/GCF_000195955.2_ASM19595v2/GCF_000195955.2_ASM19595v2_genomic.fna.gz 
gunzip GCF_000195955.2_ASM19595v2_genomic.fna.gz
mv GCF_000195955.2_ASM19595v2_genomic.fna reference_sequence.fasta


## Aligning 
#Index the reference genome

bwa index reference_sequence.fasta

# Go back to Project directory

cd ..

# Create folder for results

mkdir results

# Create folder for samfiles

mkdir ./results/samfiles

#Align sample 1
bwa mem ./data/reference_sequence.fasta ./data/sequencing_data/ERR2059824.fastq > ./results/samfiles/sample1.sam

#Align sample 10
bwa mem ./data/reference_sequence.fasta ./data/sequencing_data/ERR2059825.fastq > ./results/samfiles/sample10.sam

#Align sample 11
bwa mem ./data/reference_sequence.fasta ./data/sequencing_data/ERR2059826.fastq > ./results/samfiles/sample11.sam

#Align sample 12
bwa mem ./data/reference_sequence.fasta ./data/sequencing_data/ERR2059827.fastq > ./results/samfiles/sample12.sam

#Align sample 2
bwa mem ./data/reference_sequence.fasta ./data/sequencing_data/ERR2059828.fastq > ./results/samfiles/sample2.sam

#Align sample 3
bwa mem ./data/reference_sequence.fasta ./data/sequencing_data/ERR2059829.fastq > ./results/samfiles/sample3.sam

#Align sample 4
bwa mem ./data/reference_sequence.fasta ./data/sequencing_data/ERR2059830.fastq > ./results/samfiles/sample4.sam

#Align sample 5
bwa mem ./data/reference_sequence.fasta ./data/sequencing_data/ERR2059831.fastq > ./results/samfiles/sample5.sam

#Align sample 6
bwa mem ./data/reference_sequence.fasta ./data/sequencing_data/ERR2059832.fastq > ./results/samfiles/sample6.sam

#Align sample 7
bwa mem ./data/reference_sequence.fasta ./data/sequencing_data/ERR2059833.fastq > ./results/samfiles/sample7.sam

#Align sample 8
bwa mem ./data/reference_sequence.fasta ./data/sequencing_data/ERR2059834.fastq > ./results/samfiles/sample8.sam

#Align sample 9
bwa mem ./data/reference_sequence.fasta ./data/sequencing_data/ERR2059835.fastq > ./results/samfiles/sample9.sam


## FASTQC
# Fast quality control of all samples

cd ./data/sequencing_data

for i in {24..35}; do fastqc ERR20598$i.fastq; done

# make a new directory

mkdir fastqc_files

# move files to own folder

mv *_fastqc* ./fastqc_files

# Move back to Project folder

cd ../..


# Convert samfiles into sorted bam files and bai files

cd ./results/samfiles
for file in *.sam; do samtools view -bS $file > ${file/.sam/.bam}; done
for file in *.bam; do samtools sort $file > ${file/.bam/.sorted.bam}; done
for file in *.sorted.bam do samtools index $file; done
cd ..


## Variant calling
# SNP call using samtools mpileup 

mkdir SNP_calling
cd ..

for i in {1..12}; do samtools mpileup -g -f data/reference_sequence.fasta results/samfiles/sample$i.sorted.bam > results/SNP_calling/sample$i_variants.bcf; done

# .bcf format into .vcf format
for i in {1..12}; do bcftools call -c -v ./results/SNP_calling/sample$i_variants.bcf > ./results/SNP_calling/${file/.bcf/.vcf}; done

# View .vcf file
less -S results/SNP_calling/sample1_variants.vcf

# Calculate average coverage for all samples
for i in {1..12}; do samtools depth ./results/samfiles/sample$i.sorted.bam | awk '{sum+=$3} END {print "Average = ",sum/4411532}'; done


## Filtering

# Filter reading depth to maximum 400
mkdir ./results/filtering
for i in {1..12}; do samtools depth ./results/samfiles/sample$i.sorted.bam | awk '$3<400' | cut -f 2 > ./results/filtering/sample$i.filtered_read_depths; done


cd results/filtering
mkdir sorted_qualityscore_vcf
cd ..

# Filter quality to minimum 10 
# sort with the quality score, start from line just above the numbers, 
# (not necessery to sort, but it is nice for a quick overlook of the scores)
for i in {1..12}; do tail -n +32 SNP_calling/sample${i}_variants.vcf |sort -n -k 6 > filtering/sorted_qualityscore_vcf/sample$i.sortedqs; done

cd filtering

# keep headline, and choose the ones with quality score >10
for i in {1..12}; do awk -F"\t" 'NR==1||$6>10' sorted_qualityscore_vcf/sample$i.sortedqs > sorted_qualityscore_vcf/sample$i.filtered_quality_scores_with_scores; done

# remove top line and cut the 2nd column with IDs
for i in {1..12}; do tail -n +2 sorted_qualityscore_vcf/sample$i.filtered_quality_scores_with_scores| cut -f 2 > sample$i.filtered_quality_scores; done

# Find common id:s from filtering on depth and quality score 
for i in {1..12}; do comm -12 <(sort sample$i.filtered_read_depths) <(sort sample$i.filtered_quality_scores) > sample$i.filtered_qs_depth; done

cd ..

mkdir SNP_unique_positions

# Extract positions that are unique in the DCS-resistant samples (samples 2-12), compared to the WT sample (sample 1)
for i in {2..12}; do comm -23 filtering/sample$i.filtered_qs_depth filtering/sample1.filtered_qs_depth > SNP_unique_positions/sample$i.unique.snp.pos; done

# Go back to Project home folder

cd ..

# In the article, they found 85 unique SNPs. To see how many we found:
# Concatenate all SNPs for sample 2,…,12. Then, sort them and filter out repeated lines.
# This will result in all unique SNPs --> 105 unique SNPs

for i in {2..12}; do cat results/SNP_unique_positions/sample$i.unique.snp.pos; done | sort | uniq > results/SNP_unique_positions/all_unique_SNP_positions

# Count rows to get number of unique SNPs, resulting in 105 unique positions.

wc -l results/SNP_unique_positions/all_unique_SNP_positions

### search from file:
# place snps in a file named positions.txt in folder results/SNP_calling
# 33544
# 1837270
# 1838506
# 3246699
# 3278306
# 3278390
# 3278391
# 3314422
# 3550149
# 3840391
# 3841405

mkdir results/SNP_calling/Positions_of_interest

# grep these in another file
for i in {1..12}; do grep -f results/SNP_calling/positions.txt results/SNP_calling/sample${i}_variants.vcf > results/SNP_calling/Positions_of_interest/sample$i.SNPs_before_filtering; done

cd results/samfiles

# Make files with the read depth for every position.

for i in {1..12}; do samtools depth sample$i.sorted.bam > read_depths/sample$i.read_depths; done

# compare to file with exact text

mkdir read_depths/Positions_of_interest

for i in {1..12}; do grep -w -f read_depths/positions.txt read_depths/sample${i}.read_depths > read_depths/Positions_of_interest/sample$i.read_depths_posofinterest; done

# Go back to Project home folder

cd ../..


#### To avoid duplicate reads, test count nr of reads and average coverage
for i in {1..12}; do samtools rmdup -s sample$i.bam sample$i.bam.wo.duplicates; done
for i in {1..12}; do samtools view sample$i.bam | wc -l; done #Nr of reads without removing duplicates
for i in {1..12}; do samtools view sample$i.bam.wo.duplicates | wc -l; done #Nr of reads after removing duplicates
for file in *.bam.wo.duplicates; do samtools sort $file > ${file/.bam.wo.duplicates/.sorted.bam.wo.duplicates}; done
for i in {1..12}; do samtools depth ./results/samfiles/sample$i.sorted.bam | awk '{sum+=$3} END {print "Average = ",sum/4411532}'; done

# Convert BAM files into FASTQ to do fast quality control again
# I did it for sample 12 after duplicated were removed
samtools bam2fq results/samfiles/sample12.bam > data/sequencing_data/fastqc_files/sample12.wo.dup_fastqc.fastq


####ALTERNATIVE METHOD FOR FILTERING 
mkdir results/SNP_calling/Filter_directly
for i in {1..12}; do samtools mpileup -g -f --max-depth --min-MQ data/reference_sequence.fasta results/samfiles/sample$i.sorted.bam > results/SNP_calling/Filter_directly/sample$i_FILTERED_DIRECTLY.bcf; done

# .bcf format into .vcf format
for i in {1..12}; do bcftools call -c -v ./results/SNP_calling/Filter_directly/sample$i_FILTERED_DIRECTLY.bcf > ./results/SNP_calling/Filter_directly/${file/.bcf/.vcf}; done



######## ANNOVAR TESTING #######
# ftp://ftp.ensemblgenomes.org/pub/bacteria/release-46/fasta/bacteria_0_collection/mycobacterium_tuberculosis_h37rv/dna/
# ftp://ftp.ensemblgenomes.org/pub/bacteria/release-46/gff3/bacteria_0_collection/mycobacterium_tuberculosis_h37rv

# In directory ~/Project_Applied_Bioinformatics/annovar/annovar/tuberculosis

wget ftp://ftp.ensemblgenomes.org/pub/bacteria/release-46/gff3/bacteria_0_collection/mycobacterium_tuberculosis_h37rv/Mycobacterium_tuberculosis_h37rv.ASM19595v2.46.chromosome.Chromosome.gff3.gz
wget ftp://ftp.ensemblgenomes.org/pub/bacteria/release-46/gff3/bacteria_0_collection/mycobacterium_tuberculosis_h37rv/Mycobacterium_tuberculosis_h37rv.ASM19595v2.46.gff3.gz
wget ftp://ftp.ensemblgenomes.org/pub/bacteria/release-46/fasta/bacteria_0_collection/mycobacterium_tuberculosis_h37rv/dna/Mycobacterium_tuberculosis_h37rv.ASM19595v2.dna.chromosome.Chromosome.fa.gz

# do not forget to gunzip them

# the program gff3ToGenePred must be downloaded for this command below:

# Use the gff3ToGenePred tool to convert the GFF3 file to a GenePred file:
./gff3ToGenePred tuberculosis/Mycobacterium_tuberculosis_h37rv.ASM19595v2.46.chromosome.Chromosome.gff3 MT_refGene.txt

# Generate a transcript FASTA file with our provided script:
perl ../retrieve_seq_from_fasta.pl --format refGene --seqfile Mycobacterium_tuberculosis_h37rv.ASM19595v2.dna.chromosome.Chromosome.fa MT_refGene.txt --out MT_refGeneMrna.fa

perl table_annovar.pl <variant.vcf> MT/ --vcfinput --outfile final –buildver MT --protocol refGene --operation g
####################################
